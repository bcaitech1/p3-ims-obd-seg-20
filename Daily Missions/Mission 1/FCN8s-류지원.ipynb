{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#하이퍼파라미터-세팅-및-seed-고정\" data-toc-modified-id=\"하이퍼파라미터-세팅-및-seed-고정-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>하이퍼파라미터 세팅 및 seed 고정</a></span></li><li><span><a href=\"#학습-데이터-EDA\" data-toc-modified-id=\"학습-데이터-EDA-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>학습 데이터 EDA</a></span></li><li><span><a href=\"#데이터-전처리-함수-정의-(Dataset)\" data-toc-modified-id=\"데이터-전처리-함수-정의-(Dataset)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>데이터 전처리 함수 정의 (Dataset)</a></span></li><li><span><a href=\"#Dataset-정의-및-DataLoader-할당\" data-toc-modified-id=\"Dataset-정의-및-DataLoader-할당-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Dataset 정의 및 DataLoader 할당</a></span><ul class=\"toc-item\"><li><span><a href=\"#데이터-샘플-시각화-(Show-example-image-and-mask)\" data-toc-modified-id=\"데이터-샘플-시각화-(Show-example-image-and-mask)-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>데이터 샘플 시각화 (Show example image and mask)</a></span></li></ul></li><li><span><a href=\"#baseline-model\" data-toc-modified-id=\"baseline-model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>baseline model</a></span><ul class=\"toc-item\"><li><span><a href=\"#[TODO]-코드-구현-FCN-8s-\" data-toc-modified-id=\"[TODO]-코드-구현-FCN-8s--5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span><font color=\"red\">[TODO] 코드 구현 FCN-8s </font></a></span></li></ul></li><li><span><a href=\"#train,-validation,-test-함수-정의\" data-toc-modified-id=\"train,-validation,-test-함수-정의-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>train, validation, test 함수 정의</a></span></li><li><span><a href=\"#모델-저장-함수-정의\" data-toc-modified-id=\"모델-저장-함수-정의-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>모델 저장 함수 정의</a></span></li><li><span><a href=\"#모델-생성-및-Loss-function,-Optimizer-정의\" data-toc-modified-id=\"모델-생성-및-Loss-function,-Optimizer-정의-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>모델 생성 및 Loss function, Optimizer 정의</a></span></li><li><span><a href=\"#저장된-model-불러오기-(학습된-이후)\" data-toc-modified-id=\"저장된-model-불러오기-(학습된-이후)-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>저장된 model 불러오기 (학습된 이후)</a></span></li><li><span><a href=\"#submission을-위한-test-함수-정의\" data-toc-modified-id=\"submission을-위한-test-함수-정의-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>submission을 위한 test 함수 정의</a></span></li><li><span><a href=\"#submission.csv-생성\" data-toc-modified-id=\"submission.csv-생성-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>submission.csv 생성</a></span></li><li><span><a href=\"#Reference\" data-toc-modified-id=\"Reference-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Reference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.954382Z",
     "start_time": "2021-04-25T10:42:06.942411Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pytorch version: 1.8.0.dev20210130\nGPU 사용 가능 여부: True\nGeForce GTX 1080 Ti\n2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import label_accuracy_score\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 전처리를 위한 라이브러리\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "plt.rcParams['axes.grid'] = False\n",
    "\n",
    "print('pytorch version: {}'.format(torch.__version__))\n",
    "print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"   # GPU 사용 가능 여부에 따라 device 정보 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 세팅 및 seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T10:34:47.841930Z",
     "start_time": "2021-04-18T10:34:47.827931Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8   # Mini-batch size\n",
    "num_epochs = 20\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T10:34:47.856930Z",
     "start_time": "2021-04-18T10:34:47.842931Z"
    }
   },
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 21\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline model\n",
    "\n",
    "### <font color='red'>[TODO] 코드 구현 FCN-8s </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T16:14:30.953430Z",
     "start_time": "2021-04-18T16:14:30.924454Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 모델 참고 코드 \n",
    "# https://github.com/wkentaro/pytorch-fcn/\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FCN8s(nn.Module):\n",
    "    def __init__(self, num_classes=12):\n",
    "        super(FCN8s, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        # convolution block (3x3 and 1x1)\n",
    "        def conv_block(in_channel, out_channel, k=3, s=1, p=1, pool=True):\n",
    "            if pool:\n",
    "                return nn.Sequential(nn.Conv2d(in_channel, out_channel, k, s, p), nn.ReLU(inplace=True), nn.MaxPool2d(2, 2, ceil_mode=True))\n",
    "            else:\n",
    "                return nn.Sequential(nn.Conv2d(in_channel, out_channel, k, s, p), nn.ReLU(inplace=True))\n",
    "        \n",
    "        def conv_1x1(in_channel, out_channel):\n",
    "            return nn.Sequential(nn.Conv2d(in_channel, out_channel, 1, 1, 0), nn.ReLU(inplace=True))\n",
    "        \n",
    "\n",
    "        # stack convolution blocks (1~7)\n",
    "        channels = [3, 64, 128, 256, 512, 512, 4096, 4096]\n",
    "        conv_layers = []\n",
    "        conv_layer_names = []\n",
    "        for i in range(len(channels)-1):\n",
    "            # conv block 1~5 (3x3 conv)\n",
    "            if i < 2: # block 1~2\n",
    "                conv_layer_names += [f'conv{i+1}_1', f'conv{i+1}_2']\n",
    "                conv_layers.append(conv_block(channels[i], channels[i+1], pool=False))\n",
    "                conv_layers.append(conv_block(channels[i+1], channels[i+1]))\n",
    "            elif 1 < i < 5: # block 3~5\n",
    "                conv_layer_names += [f'conv{i+1}_1', f'conv{i+1}_2', f'conv{i+1}_3']\n",
    "                conv_layers.append(conv_block(channels[i], channels[i+1], pool=False))\n",
    "                conv_layers.append(conv_block(channels[i+1], channels[i+1], pool=False))\n",
    "                conv_layers.append(conv_block(channels[i+1], channels[i+1]))\n",
    "            # FC block 6~7 (1x1 conv)\n",
    "            else:\n",
    "                conv_layer_names += [f'FC{i+1}']\n",
    "                conv_layers.append(conv_block(channels[i], channels[i+1], 1, 1, 0, pool=False))\n",
    "        \n",
    "        # score layer (1x1 conv)\n",
    "        conv_layer_names += [f'score']\n",
    "        conv_layers.append(conv_1x1(channels[i+1], self.num_classes))\n",
    "        \n",
    "        self.net = nn.Sequential()\n",
    "        for layer, name in zip(conv_layers, conv_layer_names):\n",
    "            self.net.add_module(name, layer)\n",
    "                \n",
    "        # upsampling\n",
    "        self.upscore2 = nn.ConvTranspose2d(self.num_classes, self.num_classes, 4, 2, 1)\n",
    "        self.upscore8 = nn.ConvTranspose2d(self.num_classes, self.num_classes, 16, 8, 4)\n",
    "\n",
    "        # branches\n",
    "        sequential_layers = list(self.net.children())\n",
    "        self.branch1 = nn.Sequential(*sequential_layers[:10])\n",
    "        self.branch2 = nn.Sequential(*sequential_layers[:7])\n",
    "        \n",
    "        # summation\n",
    "        self.conv1x1_1 = conv_1x1(512, self.num_classes)\n",
    "        self.conv1x1_2 = conv_1x1(256, self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        def conv_1x1(in_channel, out_channel):\n",
    "            return nn.Sequential(nn.Conv2d(in_channel, out_channel, 1, 1, 0), nn.ReLU(inplace=True))\n",
    "\n",
    "        sequential_output = self.net(x)\n",
    "        output_1 = self.conv1x1_1(self.branch1(x)) + self.upscore2(sequential_output)\n",
    "        output_2 = self.conv1x1_2(self.branch2(x)) + self.upscore2(output_1)\n",
    "        output = self.upscore8(output_2)\n",
    "\n",
    "        return output\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FCN8s(\n  (net): Sequential(\n    (conv1_1): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n    )\n    (conv1_2): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n    )\n    (conv2_1): Sequential(\n      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n    )\n    (conv2_2): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n    )\n    (conv3_1): Sequential(\n      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n    )\n    (conv3_2): Sequential(\n      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n    )\n    (conv3_3): Sequential(\n      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n    )\n    (conv4_1): Sequential(\n      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n    )\n    (conv4_2): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n    )\n    (conv4_3): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n    )\n    (conv5_1): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n    )\n    (conv5_2): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n    )\n    (conv5_3): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n    )\n    (FC6): Sequential(\n      (0): Conv2d(512, 4096, kernel_size=(1, 1), stride=(1, 1))\n      (1): ReLU(inplace=True)\n    )\n    (FC7): Sequential(\n      (0): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n      (1): ReLU(inplace=True)\n    )\n    (score): Sequential(\n      (0): Conv2d(4096, 12, kernel_size=(1, 1), stride=(1, 1))\n      (1): ReLU(inplace=True)\n    )\n  )\n  (upscore2): ConvTranspose2d(12, 12, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n  (upscore8): ConvTranspose2d(12, 12, kernel_size=(16, 16), stride=(8, 8), padding=(4, 4))\n  (branch1): Sequential(\n    (0): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n    )\n    (2): Sequential(\n      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n    )\n    (3): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n    )\n    (4): Sequential(\n      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n    )\n    (5): Sequential(\n      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n    )\n    (6): Sequential(\n      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n    )\n    (7): Sequential(\n      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n    )\n    (8): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n    )\n    (9): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n    )\n  )\n  (branch2): Sequential(\n    (0): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n    )\n    (2): Sequential(\n      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n    )\n    (3): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n    )\n    (4): Sequential(\n      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n    )\n    (5): Sequential(\n      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n    )\n    (6): Sequential(\n      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n    )\n  )\n  (conv1x1_1): Sequential(\n    (0): Conv2d(512, 12, kernel_size=(1, 1), stride=(1, 1))\n    (1): ReLU(inplace=True)\n  )\n  (conv1x1_2): Sequential(\n    (0): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n    (1): ReLU(inplace=True)\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "model = FCN8s(num_classes=12)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T16:16:11.634792Z",
     "start_time": "2021-04-18T16:16:05.875817Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "input shape :  torch.Size([1, 3, 512, 512])\n",
      "output shape :  torch.Size([1, 12, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "# 구현된 model에 임의의 input을 넣어 output이 잘 나오는지 test\n",
    "\n",
    "model = FCN8s(num_classes=12)\n",
    "x = torch.randn([1, 3, 512, 512])\n",
    "print(\"input shape : \", x.shape)\n",
    "out = model(x).to(device)\n",
    "print(\"output shape : \", out.size())\n",
    "\n",
    "model = model.to(device)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "297.278px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "metadata": {
   "interpreter": {
    "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}